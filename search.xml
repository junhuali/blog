<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[提升国内服务器Github clone速度的方法]]></title>
    <url>%2F2018%2F04%2F18%2Fraise-github-clone-speed%2F</url>
    <content type="text"><![CDATA[Github 速度慢众所周知的原因，国内的vps 从Github 上clone 源码的速度感人。于是查了一下，发现有两种方法可以提升从GitHub clone 代码的速度。 修改hosts从http://github.global.ssl.fastly.net.ipaddress.com/ 可以获取到速度比较快的ip，通过替换hosts ，达到加速的目的。 123vim /etc/hosts# GitHub Start151.101.113.194 github.global.ssl.fastly.net 保存后自动生效 通过下载Spring Boot 的源码，见上图，速度还不错。 通过代理提升本地的速度一般我们都是使用ss的本地socks5代理，速度多快，取决于提供服务的vps的速度。1234git config --global --unset http.proxygit config --global --unset https.proxygit config --global http.proxy 'socks5://127.0.0.1:1080'git config --global https.proxy 'socks5://127.0.0.1:1080' 上面的配置需要注意自己的socks5 端口，Mac 和 Windows的一般是1080，Mac的根据自己设置的进行修改，比如我的是1086，所以需要改成socks5://127.0.0.1:1086。 通过上面的两个方法，可以大幅提升服务器和本地的GitHub代码clone 速度，解决漫长的等待，特别是比较大的仓库。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty 学习记录]]></title>
    <url>%2F2018%2F04%2F11%2Fnetty-study%2F</url>
    <content type="text"><![CDATA[Netty 核心组件 Channel 回调 Future 事件和ChannelHandlerChannelChannel 是Java NIO 的一个基本构造，是数据的载体，可以被打开或者关闭，连接或者断开连接。回调一个回调就是一个方法，一个指向已经被提供给另外一个方法的方法的引用。Netty 中使用回调来处理事件。FutureFuture 提供了另一种在操作完成时通知应用程序的方式。ChannelHandlerChannelHandler 是 Netty]]></content>
  </entry>
  <entry>
    <title><![CDATA[学习Shell命令行总结]]></title>
    <url>%2F2018%2F04%2F02%2Fstudy-shell%2F</url>
    <content type="text"><![CDATA[了解linux系统内核内核的主要作用 系统内存管理 软件程序管理 硬件设备管理 文件系统管理 什么是虚拟内存内核通过硬盘上的存储空间来实现虚拟内存，这块区域称为交换空间（swap space）。平常使用的都是阿里云，发现阿里云把swap的空间为0。查看官方文档后发现如果使用普通云盘，不建议使用swap分区，原因是因为开启SWAP可能会因频繁换页操作，导致IO性能下降，如果内存足够的情况下，建议关闭swap 分区。 软件程序管理Linux操作系统将运行中的程序称为进程。进程可以在前台运行，将输出显示在屏幕上，也可以在后台运行。内核创建第一个进程称为init进程，来启动系统上其他进程，并将其加载到虚拟内存中。 一些Linux发行版使用一个表来管理在系统开机时要自动启动的进程。在Linux系统上，这个表通常位于/etc/inittab中。另外一些系统则采用/etc/init.d目录，将开机时启动或停止某个应用的脚本放在这个目录下。 Linux 操作系统的init系统采用了运行级。运行级决定了init进程运行/etc/inittab文件或者/etc/rcX.d目录中定义好的某些特定类型的进程。Linux操作系统有5个启动运行级。（但是在使用centos7的时候发现有7个运行级别0-6） CentOS系统有7个运行级别(runlevel) 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆运行级别2：多用户状态(没有NFS)运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式运行级别4：系统未使用，保留运行级别5：X11控制台，登陆后进入图形GUI模式运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 不过在centos7中使用Systemd 取代init，init 是串行的，启动速度比较慢。 硬件设备管理内核的另外一个作用就是管理硬件设备。如果使用硬件，都需要在内核代码中加入其驱动程序代码。在Linux中有两种方法插入设备驱动 编译进内核的设备驱动代码 可插入内核的设备驱动代码（这种方式比较方便，利于维护） 文件系统管理Linux 内核通过支持通过不同类型的文件系统从硬盘中读写数据。这样可以支持多种文件系统，需要内核在编译时就加入可能用到的文件系统的支持。]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Let‘s Encrypt创建免费SSL证书（官方文档自动获取泛域名证书还不完善）]]></title>
    <url>%2F2018%2F03%2F17%2FLets-Encrypt-free-wildcard-domain-name%2F</url>
    <content type="text"><![CDATA[网络安全越来越重要，很多的网站都开始使用https来增加网站的安全性，Let’s Encrypt 最近支持了泛域名SSL证书，这样一个域名只需要一个SSL证书就搞定了，之前阿里云等云服务商提供了免费的SSL证书，但是只支持一个子域名一个证书，最多20个（一般人其实够用了），但是申请多个证书还是比较麻烦，而且很重要的一个原因，云服务商提供的通配符证书价格很贵，使用Let’s Encrypt费用就可以省了，唯一需要做的就是要进行证书续期。 申请域名为了演示，需要申请一个免费域名,我是在freenom申请的，freenom自带的有免费的DNS解析，但是在国内的体验不是很好所以为了更好的体验，使用dnspod。 免费的域名和DNS服务商有很多，大家可以自己去选择，上面只是举个例子。 我申请的域名是rubys.ml,可以免费使用一年，续费的话不到10刀/年。 配置Let’s Encrypt 单域名首先访问Let’s Cncrypt官网，Get Started，然后会提供两种方式，With Shell Access和Without Shell Access， With Shell Access(官方推荐通过shell进行部署)使用Certbot ACME客户端进行部署，它可以自动执行证书颁发和安装，而不用停机，它很容易使用，适用于多种操作系统，并且具有出色的文档。访问certbot,选择自己使用的服务器和操作系统。有自动化和高级两种模式可以选择。这里选择自动化。 安装系统扩展包 1234wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmrpm -ivh epel-release-latest-7.noarch.rpmyum -y install yum-utilsyum-config-manager --enable rhui-REGION-rhel-server-extras rhui-REGION-rhel-server-optional 安装certbot 1sudo yum install certbot-nginx 运行certbot插件生成证书 1sudo certbot --nginx 重启nginx1systemctl restart nginx 访问www.rubys.ml,发现链接自动定向到https://www.rubys.ml 增加自动续期12crontab -e0 0,12 * * * python -c 'import random; import time; time.sleep(random.random() * 3600)' &amp;&amp; certbot renew 上面的方法是单域名证书的创建 配置Let’s Encrypt 泛域名如果配置泛域名，还需要安装一个 Certbot&#39;s DNS plugins 插件目前的代码还不够完善，目前根据文档，可以看到只支持，通过Docker 安装，可以一次性获取下面的服务商的支持 certbot-dns-cloudflare certbot-dns-cloudxns certbot-dns-digitalocean certbot-dns-dnsimple certbot-dns-dnsmadeeasy certbot-dns-google certbot-dns-luadns certbot-dns-nsone certbot-dns-rfc2136 certbot-dns-route53 目前支持的云服务商还不多阿里云的话可以使用如下脚本https://github.com/Neilpang/acme.sh从云服务商那里获取对应的APIKey，APISecret，填入脚本,具体参考上面地址中的文档。 未完待续。。。]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Domain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python通过使用requirements.txt文件记录管理依赖包]]></title>
    <url>%2F2018%2F03%2F07%2Fpython-requirements%2F</url>
    <content type="text"><![CDATA[python在本地使用的时候，不需要关心使用的依赖的问题，但是将代码上传到服务器以后，服务器上可能没有对应的包，这个时候程序运行就会报错，所以为了程序能够正常启动，就需要使用requirements.txt来记录版本依赖，有点类似Java中的Maven,管理Jar包。 使用1234# 进入项目目录创建requirements.txt文件touch requirements.txt# 将项目中使用的包冻结（freeze）到requirements.txt文件中pip freeze &gt;requirements.txt 当把项目上传到服务器以后可以执行下面的命令安装对应的包12#通过requirements.txt 文件中的记录安装依赖pip install -r requirements.txt 通过上面的方法就能将本地的包安装在服务器上了，保证了两个环境中的依赖一致，一般情况是在虚拟环境中使用，保证环境的干净，避免发生冲突。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 入门]]></title>
    <url>%2F2018%2F03%2F07%2Fpthon-tutorial%2F</url>
    <content type="text"><![CDATA[Life is short, you need Python. 上面那句话可能大家耳熟能详的一句话了，形象的表达了Python。有时候一些简单的功能验证或者是文本处理等，用Java等语言实现需要很长的时间，这个时候用Python你会发现，短短几行就搞定了，剩下的时间你就可以去喝咖啡了。 基本数据类型了解过几种语言后，会发现其实语言之间有很大的共通性。学习基本的数据类型之后，加上一些基本的语法，就能写起来了，慢慢的在写的过程中，熟悉语言的细节，用好每个语言的技巧，每个语言的出现都是为了解决一些其他语言没法解决的问题。 Python 基本数据类型（6个标注数据类型） Number (数字) String (字符串) List (列表) Tuple (元组) Sets (集合) Dictionary (字典) 待续。。。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps实践2:Spring Boot集成Docker环境]]></title>
    <url>%2F2018%2F02%2F27%2Fdevops-2-springboot-docker-integrated%2F</url>
    <content type="text"><![CDATA[知之愈明,则行之愈笃；行之愈笃,则知之益明.——朱熹（宋） 我们在平常学习了很多的知识，但是如果没有深入去实践，知识掌握就不会牢固，所以需要通过实践来巩固。现在大多数的业务都切换到了Spring Boot，更加复杂和庞大的业务则使用Spring Cloud，当然也有用Dubbo，所以准备在Spring Boot中集成Docker，进行服务化。 创建项目进行集成创建一个Spring Boot 项目 增加项目对Docker的支持 修改pom.xml配置，增加对应的插件，可以使用Maven进行打包 12#Docker 镜像前缀，放在&lt;properties&gt; 标签中 &lt;docker.image.prefix&gt;devops&lt;/docker.image.prefix&gt; 添加视图模板支持 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 增加对应的maven 插件，插件有多种，这里采用 com.spotify 123456789101112131415161718192021222324252627282930313233343536&lt;build&gt; &lt;finalName&gt;devops&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- docker打包 --&gt; &lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;configuration&gt; &lt;serverId&gt;docker-hosted&lt;/serverId&gt; &lt;!-- docker仓库地址，用于推送镜像 --&gt; &lt;registryUrl&gt;$&#123;docker.repository&#125;&lt;/registryUrl&gt; &lt;!-- 设置为false，避免自动推送镜像 --&gt; &lt;pushImage&gt;false&lt;/pushImage&gt; &lt;!-- Dockerfile路径 --&gt; &lt;dockerDirectory&gt;src/main/docker&lt;/dockerDirectory&gt; &lt;!-- 构建的镜像名称 --&gt; &lt;imageName&gt;$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125;&lt;/imageName&gt; &lt;imageTags&gt; &lt;imageTag&gt;latest&lt;/imageTag&gt; &lt;/imageTags&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 修改Maven settings 文件配置（主要的目的是为了方便后面我们将自己的服务推送到自己的私服，方便管理） 1234567891011121314151617&lt;pluginGroups&gt; &lt;pluginGroup&gt;com.spotify&lt;/pluginGroup&gt;&lt;/pluginGroups&gt;#本地私服的配置&lt;/profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;properties&gt; &lt;docker.repository&gt;http://192.168.100.77:8081/repository/docker&lt;/docker.repository&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt;#激活私服配置&lt;activeProfiles&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt; &lt;/activeProfiles&gt; 上面基本的pom配置就完成了，之后开始配置Docker相关的脚本 Docker脚本配置在src/main 目录下创建docker 文件夹，刚刚上面的pom配置里声明了Dockerfile的路径创建文件Dockerfile ，注意文件没有后缀，之后增加如下脚本1234FROM java:8 #基本镜像VOLUME /tmp #挂载文件位置，/tmp 为临时目录ADD devops.jar app.jar #添加对应的jar，使用maven打包后会自动到target目录找devops.jar 文件ENTRYPOINT ["java","-Djava.security.egd=file:/dev/./urandom","-jar","/app.jar"] # 程序启动入口 打包、运行镜像创建对应的测试文件，打包1mvn clean package docker:build # 一气呵成O(∩_∩)O~~ 在运行docker命令前，先确认电脑上的docker环境是否配置成12345678910111213141516171819docker version# 会有如下显示Client: Version: 17.12.0-ce API version: 1.35 Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:03:51 2017 OS/Arch: darwin/amd64Server: Engine: Version: 17.12.0-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:12:29 2017 OS/Arch: linux/amd64 Experimental: true 上面说明Docker是正常启动的 然后查看镜像1docker images 上图说明我们的镜像打包成功然后运行一下，检查镜像是否能够正常启动123#启动镜像 -d 表示后台运行，-p 端口进行映射 --name docker服务名称 devops/devops:latest 运行的镜像docker run -d -p 8080:8080 --name devops devops/devops:latest#执行docker ps 查看镜像是否运行 如果，说明服务是正常启动了，之后请求http://localhost:8080/index?name=World能够请求成功，说明镜像部署成功 停止释放镜像123# 养成好习惯，停止释放镜像docker stop 2026e45bc2cedocker rm 2026e45bc2ce 代码可在https://github.com/junhuali/devops-springboot 下载]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>SpringBoot</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7 安装 pyenv]]></title>
    <url>%2F2018%2F02%2F27%2Fcnetos-install-pyenv%2F</url>
    <content type="text"><![CDATA[人生苦短，我用Python Python 短小精悍，在很多小地方使用Python，能提升效率，产生更大的价值。一般我们更多的是在本地使用，或者一个人使用，但是在服务器上，可能存在多人使用的情况，所以需要不同版本的Python，手动安装很容易冲突，所以采用环境管理来进行管理。 安装Pyenv1sudo yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel #安装所需的包 12345678#创建目录、安装mkdir ~/.pyenvgit clone git://github.com/yyuu/pyenv.git ~/.pyenv #配置环境变量echo 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.bashrc echo 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.bashrc echo 'eval "$(pyenv init -)"' &gt;&gt; ~/.bashrc exec $SHELL -l 12345678910111213``` bash#列出所有版本pyenv install --list#安装python 3.5.2pyenv install 3.5.2#全局使用pyenv global 3.5.2#检查版本python --version 通过环境管理，一台服务器上可以存在多个环境，方便部署。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DevOps实践1:基本概念和环境配置]]></title>
    <url>%2F2018%2F02%2F26%2Fdevops-1-environmental-configuration%2F</url>
    <content type="text"><![CDATA[什么是DevOps DevOps（英文Development和Operations的组合）是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运营工作必须紧密合作。 我认为DevOps更应该是一种工程师文化，促进研发、测试和运维之间的沟通和闭环协作，共同达成业务目标。同时需要相应的流程和工具去配合，并简化工作，提升效率。 DevOps各个阶段 第一阶段：流程化基于Jenkins和Docker进行实施，能够初步将持续构建、持续部署、持续发布连接在一起，减少手工配置，提升效率（基于本地环境进行实践，尽可能测试出问题，为线上环境做准备）。 第二阶段：自动化服务（部分）基于阿里云EDAS，基本生产环境的服务全部部署在阿里云，通过使用阿里云的服务为线上的应用提供运维、发布、回滚、监控、诊断等；此阶段准备将部分非核心服务进行DevOps化；同时引入自动化测试，UI自动化、接口自动化，提高测试效率。 第三阶段：智能化根据实际的业务情况，通过DevOps提升开发、测试、运维效率 工具说明目前处于第一阶段，希望通过相应的工具链提升开发的效率，进行持续构建、持续部署（dev、test两个环境），同时在线下环境进行实验。所需要用到的软件和工具: Jenkins Dokcer IDEA Git主要是上面几种工具，尽可能使用少量的工具，减少开发、测试、运维的学习压力，方便快速上手，同时需要使用的其他软件包会在文档里面列出。 Docker 环境配置因为众所周知的原因，Docker的下载速度在国内下载速度比较慢，所以采用镜像地址进行安装。 Windows 环境 Docker for Windows 在Windows上运行Docker。系统要求，Windows10x64位，支持Hyper-V。https://dn-dao-github-mirror.qbox.me/docker/install/windows/InstallDocker.msi参考’http://www.widuu.com/docker/installation/windows.html‘ Mac 环境 Docker for Mac 在Mac上运行Docker。系统要求，OS X 10.10.3 或者更高版本，至少4G内存，4.3.30版本以前的VirtualBox会与Docker for Mac产生冲突，所以请卸载旧版本的VitrualBox。https://dn-dao-github-mirror.qbox.me/docker/install/mac/Docker.dmg可参考：http://blog.csdn.net/jiang_xinxing/article/details/58025417 Linux 环境 12#执行以下脚本可以高速安装（适用于Ubuntu，Debian,Centos等大部分Linux）curl -sSL https://get.daocloud.io/docker | sh 如果您的电脑版本过旧，可以使用 Docker Toolbox 在Windows或者Mac上运行Docker。适用于Mac OS X 10.8+ 或者 Windows 7/8.1。https://get.daocloud.io/toolbox/ (自行下载相应的版本，window的选exe文件，Mac 选pkg文件) Docker 常用命令1docker search XXX #查询docker镜像 1docker pull XXX #拉取docker 镜像 1docker images #查看已下载的docker镜像 1docker run XXX #运行docker容器 1docker ps #查看正在运行的docker容器 1docker stop XXX #停止正在运行的容器 1docker rm -f XXX #删除容器 要想更好的使用Docker和各种技术需要不断充电和探索。 部分图片来自 http://blog.csdn.net/ghostcloud2016/article/details/62426612]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitee码云使用webhook]]></title>
    <url>%2F2018%2F02%2F25%2Fgitee-with-webhook%2F</url>
    <content type="text"><![CDATA[原因我们经常使用GitHub、GitLab、Gitee 之类的仓库，有时候需要频繁的发布代码打包，人工发布，工作量有时候会很大，有时候还容易出错，所以会使用Jenkins一类的工具进行辅助，但是如果是一个简单的项目或者是个人项目使用Jenkins就显得太重了，可以直接使用webhook，比较方便。 什么是webhook 准确的说webhoo是一种web回调或者http的push API，是向APP或者其他应用提供实时信息的一种方式。Webhook在数据产生时立即发送数据，也就是你能实时收到数据。这一种不同于典型的API，需要用了实时性需要足够快的轮询。这无论是对生产还是对消费者都是高效的，唯一的缺点是初始建立困难。 Webhook有时也被称为反向API，因为他提供了API规则，你需要设计要使用的API。Webhook将向你的应用发起http请求，典型的是post请求，应用程序由请求驱动。 配置webhook知道什么是webhook 后我们就要开始配置我们自己的项目了。环境： CentOS7 Gitee（网上GitHub的教程比较多，这个基于码云） 配置项目公私钥 生产公钥 1234ssh-keygen -t rsa -C "xxxxx@xxxxx.com" # Generating public/private rsa key pair...# 三次回车即可生成 ssh key 查看公钥 12cat ~/.ssh/id_rsa.pub# ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC6eNtGpNGwstc.... 添加公钥 测试12ssh -T git@gitee.comWelcome to Gitee.com, yourname! # 返回，说明正常 配置服务器node环境 安装nvm，服务器上使用nvm 方便多版本node切换 12345678curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh | bashvim /etc/profile#加入下面的内容export NVM_DIR="$HOME/.nvm"[ -s "$NVM_DIR/nvm.sh" ] &amp;&amp; \. "$NVM_DIR/nvm.sh"source /etc/profilenvm install stable # 安装稳定版nvm current # 查看当前的版本 配置相关的脚本安装gitee-webhook-handler(GitHub,GitLab,gitee 的包是不同的，不能混用) 123mkdir /opt/webhook #创建目录cd /opt/webhooknpm install -g gitee-webhook-handler # 当前的版本为v0.1.2 创建对应的webhook服务 1234567891011121314151617181920212223242526272829303132vim webhook.jsvar http = require('http')var createHandler = require('gitee-webhook-handler')var handler = createHandler(&#123; path: '/webhooks_push', secret: '123456' &#125;)# post 所需要用到的秘钥function run_cmd(cmd, args, callback) &#123; var spawn = require('child_process').spawn; var child = spawn(cmd, args); var resp = ""; child.stdout.on('data', function(buffer) &#123; resp += buffer.toString(); &#125;); child.stdout.on('end', function() &#123; callback (resp) &#125;);&#125;handler.on('error', function (err) &#123; console.error('Error:', err.message)&#125;)handler.on('Push Hook', function (event) &#123; # 这个地方就是GitHub 和 Gitee 不一样的地方，需要注意 console.log('Received a push event for %s to %s', event.payload.repository.name, event.payload.ref); run_cmd('sh', ['./deploy.sh'], function(text)&#123; console.log(text) &#125;);# 需要执行的脚本位置&#125;)try &#123; http.createServer(function (req, res) &#123; handler(req, res, function (err) &#123; res.statusCode = 404 res.end('no such location') &#125;) &#125;).listen(6666) # 服务监听的端口，可以自行修改&#125;catch(err)&#123; console.error('Error:', err.message)&#125; 创建需要执行的脚本 12vim deploy.shgit pull xxxxx # 根据自己的需要自行编写 测试服务显示ok，说明成功 使用pm2应用进程管理器使用node 启动服务不是很方便，推荐使用pm2123npm install -g pm2pm2 start webhook.jspm2 monit # 可以通过此命令查看服务的状态 上图显示了一些应用的基本信息，可以更好的观察到服务的状态 结束配置完成后，只要pull代码到仓库，就会触发webhook执行脚本，十分的方便，同时减少了工作量，相对采用轮询的方式消耗的资源更小。 参考：https://www.npmjs.com/package/gitee-webhook-handler]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 安装 node]]></title>
    <url>%2F2018%2F02%2F09%2Fnode-install%2F</url>
    <content type="text"><![CDATA[下载node1wget https://nodejs.org/dist/v8.9.4/node-v8.9.4-linux-x64.tar.xz 解压&amp;配置12tar xvJf node-v8.9.4-linux-x64.tar.xzmv node-v8.9.4-linux-x64 /opt 1vim /etc/profile 1234#设置node 环境变量export NODE_HOME=/opt/node-v8.9.4-linux-x64export PATH=$NODE_HOME/bin:$PATHsource /etc/profile 测试是否成功1node -v 或者安装nvm123456curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh | bashvim /etc/profile#加入下面的内容export NVM_DIR="$HOME/.nvm"[ -s "$NVM_DIR/nvm.sh" ] &amp;&amp; \. "$NVM_DIR/nvm.sh" # This loads nvm、source /etc/profile 检查是否安装成功1nvm --version 安装node123nvm install stable # 安装稳定版nvm current # 查看当前的版本nvm ls # 列出所有版本]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Node</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 创建MySQL]]></title>
    <url>%2F2018%2F01%2F17%2Fdocker-create-mysql%2F</url>
    <content type="text"><![CDATA[不要在生产环境中使用，在开发和测试阶段使用比较方便拉取镜像1docker pull mysql 创建volume （比较方便，用完方便删除）1docker volume create --name mysql-data 启动镜像123456docker run --restart="always" -d \ -v mysql-data:/var/lib/mysql \ -v /etc/localtime:/etc/localtime \ -p 0.0.0.0:3306:3306 --name mysql \ -e MYSQL_ROOT_PASSWORD=xxx mysql:latest \ --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci restart=&quot;always&quot; docker 重启后自动启动/etc/localtime:/etc/localtime 解决mysql 时区问题MYSQL_ROOT_PASSWORD 设置你自己的密码，默认用户名root--character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 设置字符集，默认需要修改，根据官方文档，可以在创建的时候指定]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7搭建socks5 服务]]></title>
    <url>%2F2018%2F01%2F15%2Fsocks5-server%2F</url>
    <content type="text"><![CDATA[环境基于centsOS 7ss5-3.8.9-8 下载源文件12345wget https://nchc.dl.sourceforge.net/project/ss5/ss5/3.8.9-8/ss5-3.8.9-8.tar.gz#配置编译环境及安装编译SS5依赖组件yum -y install gcc automake makeyum install gcc openldap-devel pam-devel openssl-devel 安装12345tar xf ss5-3.8.9-8.tar.gzmv ss5-3.8.9-8 ss5cd ss5./configuremake &amp;&amp; make install 启动脚本加执行权限1chmod +x /etc/init.d/ss5 进行配置并启动12345678910111213vi /etc/sysconfig/ss5 SS5_OPTS=" -u root -b 0.0.0.0:18080" #绑定端口为18080systemctl start ss5 #启动服务#增加用户登录权限vi /etc/opt/ss5/ss5.conf auth 0.0.0.0/0 - u permit u 0.0.0.0/0 - 0.0.0.0/0 - - - - -#设置用户名和密码，一个用户和密码一行，用空格间隔vi /etc/opt/ss5/ss5.passwd user1 123456user2 123456]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Socks5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字货币入门]]></title>
    <url>%2F2018%2F01%2F04%2FBTC-Tutorial%2F</url>
    <content type="text"><![CDATA[前言最近数字货币非常火，发现很多朋友都想入门，但是不知道怎么进行（入场当韭菜），我就随便写写。 怎么入场交易分为场外和场内，首先需要将手里的RMB，或者其他货币（即 法币），换成对应的数字货币，这样就需要进行场外交易，付钱给有数字货币的朋友，然后从他们手中获取等值的数字货币，一般这样的交易需要交易所平台做担保（避免被骗），建议用实时性比较强的到账方式，不管是买还是卖。我主要是在火币进行兑换，也叫OTC（场外交易） www.huobi.pro]]></content>
      <categories>
        <category>数字货币</category>
      </categories>
      <tags>
        <tag>数字货币</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式基础知识总结]]></title>
    <url>%2F2017%2F12%2F07%2Fregular-expression-basic%2F</url>
    <content type="text"><![CDATA[最近项目需要爬取一些网站的数据，于是我开始了爬虫生涯。以前只是简单的玩过一些爬虫，了解过nutch（分布式爬虫），Python下的scrapy等爬虫项目。因为公司的技术栈都是基于Java的，所以我简单的看了下GitHub，选择了code4craft的webmagic作为项目的基础组件。 对于爬虫来说，数据的获取是基本，获取到数据后需要进行数据清洗之后入库，XPath、正则表达式就是获取这些数据的利器，所以我们只要掌握这些技能就能很好的获取到我们需要的数据。 [0-9]这种形式的正则表达式称作字符组、字符集。\d 字符组简写。(.) 匹配任意字符，通配符，一般不匹配行起始符。]]></content>
      <categories>
        <category>Regular</category>
      </categories>
      <tags>
        <tag>Regular</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 安装 RabbitMQ 集群]]></title>
    <url>%2F2017%2F12%2F04%2Fdocker-install-rabbitmq-cluster%2F</url>
    <content type="text"><![CDATA[Docker 有个好处就是方便折腾，下面将使用bijukunjummen 提供的docker-rabbitmq-cluster 脚本进行安装。 安装docker-compose 检查是否安装过docker-compose 1$ docker-compose -v #出现docker-compose version 1.16.1, build 6d1ac21 类似，说明安装成功 如果没有安装docker-compose，进行安装 123#服务器安装$ curl -L https://get.daocloud.io/docker/compose/releases/download/1.17.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose$ chmod +x /usr/local/bin/docker-compose 在windows 和 Mac 下载对应的安装包进行安装Windows下载地址Mac下载地址 下载对应的脚本1$ git clone https://github.com/bijukunjummen/docker-rabbitmq-cluster.git 启动12$ cd docker-rabbitmq-cluster/cluster/$ docker-compose up -d #启动 备注 登录的账号密码（可以自行在脚本里面修改）user: myuserpassword: mypass然后访问localhost:15672进行访问 以上使用bijukunjummen 的脚本，可参见github以及daocloud docker-compose脚本]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用kubeadm安装kubernetes集群(待续)]]></title>
    <url>%2F2017%2F12%2F02%2Fkubeadm-install-kubernetes%2F</url>
    <content type="text"><![CDATA[因为国内服务器无法访问google，所以服务器需要科学上网可以看我之前的文章，服务器科学上网 安装docker建议使用daocloud提供的脚本进行安装，速度很快12$ curl -sSL https://get.daocloud.io/docker | sh #适用于Ubuntu，Debian,Centos等大部分Linux，会3小时同步一次Docker官方资源$ systemctl enable docker &amp;&amp; systemctl start docker #设置开机启动，启动docker 安装kubeadm, kubelet and kubectl123456789101112$ cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOF$ setenforce 0 #关闭SELinux$ yum install -y kubelet kubeadm kubectl$ systemctl enable kubelet &amp;&amp; systemctl start kubelet # 设置开机启动，启动 安装的过程有失败，提示执行yum –enablerepo=kubernetes clean metadata1234$ yum --enablerepo=kubernetes clean metadata # 如果还是不行，需要先清理缓存$ yum clean metadata$ yum clean all$ rm -rf /var/cache/yum 使用 kubeadm 创建集群1$ kubeadm init #初始化 待续。。。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器科学上网]]></title>
    <url>%2F2017%2F12%2F02%2Fserver-over-the-wall%2F</url>
    <content type="text"><![CDATA[因为服务器使用的需要从google下载东西，但是在现在的环境下是无法下载的，所以就整理了一下下面的方法进行服务器科学上网。 准备 两台vps（一台国内，一台国外），国外的可以开阿里云按时计费的，比较方便,此文档基于centos7.4 privoxy 包 开始先用ssh 命令进行服务器socks5 连接接12$ ssh -f -N -D bindaddress:port name@server$ ssh -f -N -D 0.0.0.0:1080 root@45.63.61.77 -f输入密码后进入后台模式(Requests ssh to go to background just before command execution.) -N不执行远程命令,用于端口转发( Do not execute a remote command. This is useful for just for warding ports (protocol version 2 only).) -Dsocket5代理(Specifies a local “dynamic” application-level port forwarding.Currently the SOCKS4 and SOCKS5 protocols are supported, and ssh will act as a SOCKS server.) -Ltcp转发(Specifies that the given port on the local (client) host is to be forwarded to the given host and port on the remote side.) -C使用数据压缩,网速快时会影响速度(Compression is desirable on modem lines and other slow connections, but will only slow down things on fast networks.The compression algorithm is the same used by gzip) bindaddress ：指定绑定ip地址port ： 指定侦听端口name： ssh服务器登录名server： ssh服务器地址 运行完上面的命令就进行socks5连接了可以执行下面的命令查看端口是否打开1$ netstat -nltp 如果能看到指定的端口打开(1080端口)就说明正常连接了。 安装privoxy1$ yum install privoxy -y # 使用yum 安装比较方便，也可以使用源码安装 安装完成后需要进行配置，否则无法正常访问12345$ vim /etc/privoxy/config# :783: 找到 783行，去掉前面的注释符号，端口可以随便改$ listen-address 127.0.0.1:8118#:1336: 找到 1336行，去掉前面的注释符号，后面的1080端口要对应ss服务里面的配置，要一致$ forward-socks5t / 127.0.0.1:1080 修改环境变量开启代理1234vi /ect/profileexport https_proxy=http://127.0.0.1:8118export http_proxy=http://127.0.0.1:8118# 之后执行source /etc/profile 使配置生效 启动privoxy、测试12$ privoxy /etc/privoxy/config #netstat -ntlp 查看8118端口$ wget www.google.com # 如果能下载则说明成功 后记使用完后记得关闭代理，否则所有流量都会走代理，访问可能会变慢注释掉/etc/profile 内的内容，刷新配置。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 常用命令(待完善)]]></title>
    <url>%2F2017%2F11%2F30%2Fcommon-commonds%2F</url>
    <content type="text"><![CDATA[列出所有并删除已停止容器12$ docker rm -v $(docker ps -aq -f status=exited)$ docker volume rm $(docker volume ls -qf dangling=true) 创建数据卷1$ docker volume create --name data]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine-Learning-in-Java-1]]></title>
    <url>%2F2017%2F11%2F20%2FMachine-Learning-in-Java-1%2F</url>
    <content type="text"><![CDATA[机器学习的主要方法 监督学习 无监督学习 强化学习 监督学习检测信用卡欺诈。学习算法会学习所有带有“正常” 或 “可疑”标记（向量Y）的信用卡交易（矩阵X），并最终产生一个决策模型（f函数），对未见过的交易打标记（“正常”或“可疑”）。 无监督学习无监督学习算法所学的数据没有给定的结果标签Y，它主要学习数据结构，比如将相似的输入数据归入某个聚类。可以用于推荐系统，学习算法会发现购物者一同购买的相似商品，比如购买了书A的人也购买了书B。 强化学习强化学习从完全不同的角度处理学习过程。强化学习的目标是找到最优策略，即映射函数，指定每个状态要采取的行为动作，而没有指导者明确告诉这样做是否会实现目标状态。强化学习的一个例子就是汽车自动驾驶程序。 机器学习应用流程（1） 数据与问题定义（2）数据收集（3）数据预处理（4）利用无监督学习与监督学习进行数据分析与建模（5）模型评价 特性 | 称名 | 顺序 | 等距 | 等比 | 特性 称名 顺序 等距 等比 频率分布 √ √ √ √ 中位数和众数 √ √ √ 值顺序已知 √ √ √ 每个值之间的不同可以量化 √ √ √ 值可以加减 √ √ 值可以乘除 √ 拥有真0点 √ 获取数据的方式 维基百科 网页抓取 IMDb Million Song Dataset 数据采集陷阱 幸存者偏差数据清洗填充缺失值剔除异常值数据转换 数据归纳奇异值分解（SVD）主成分分析（PCA）神经网络自动编码器（Neural nets auto encoders） 无监督学习n维欧氏空间中，两个元素之间的距离基于元素在这个空间中的位置，常称为“p-范数距离”(p-norm distance)。常用的两个距离度量是L2与L1范数距离。 L2范数也叫欧氏距离，它是最常用的距离度量，用于度量二维空间中的两个元素相距多远。它是两个元素在每个维度上差的平方和的平方根，计算公式如下: 注： 以上数据来自 Machine Learning in Java]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 安装 git]]></title>
    <url>%2F2017%2F11%2F06%2Fcentos-install-git%2F</url>
    <content type="text"><![CDATA[源码安装 安装对应的依赖 12yum install curl-devel expat-devel gettext-devel openssl-devel zlib-develyum install gcc perl-ExtUtils-MakeMaker 下载源码编译安装 确保系统git 已经被卸载1yum remove git(先执行本选项，确保卸载掉git) 123456789cd /usr/srcwget https://www.kernel.org/pub/software/scm/git/git-2.9.3.tar.gztar xzf git-2.9.3.tar.gzcd git-2.9.3make prefix=/usr/bin/git allmake prefix=/usr/bin/git installecho "export PATH=$PATH:/usr/bin/git/bin" &gt;&gt; /etc/bashrcsource /etc/bashrcgit --version (查看是否安装完成) rpm 安装（基于CentOS7）1234567# 下载最新rpmwget https://centos7.iuscommunity.org/ius-release.rpm# 安装依赖（可能会少包，按提示安装）rpm -Uvh ius-release*rpm# 安装gityum --enablerepo=ius-archive install git2ugit --version yum 安装(安装2.x 可以yum search git 搜索到)12yum install git2ugit --version]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu安装LAMP]]></title>
    <url>%2F2017%2F10%2F28%2Fubuntu-install-lamp%2F</url>
    <content type="text"><![CDATA[LAMP Linux+Apache+Mysql/MariaDB+Perl/PHP/Python一组常用来搭建动态网站或者服务器的开源软件，本身都是各自独立的程序，但是因为常被放在一起使用，拥有了越来越高的兼容度，共同组成了一个强大的Web应用程序平台。 环境基于Ubuntu 开始1$ apt-get update &amp;&amp; sudo apt-get upgrade #更新软件包 安装MySQL123$ sudo apt-get install -y mysql-server$ sudo apt-get install -y mysql-client! 记得设置默认密码 1$ sudo netstat -tap | grep mysql #显示监听的端口即表示安装成功 配置远程连接12$ vim /etc/mysql/mysql.conf.d/mysqld.cnf#bind-address = 127.0.0.1 远程访问赋权12345$ mysql -u root -p$ grant all on *.* to root@'%' identified by 'root';$ flush privileges; $ exit$ service mysql restart(or: $ /etc/init.d/mysql restart)# 重启 ####安装Apache2 1$ sudo apt-get install -y apache2 1234567891011121314151617#修改apache2.conf配置$ vi /etc/apache2/apache2.conf$ KeepAlive Off#修改mpm_prefork.conf配置$ vim /etc/apache2/mods-available/mpm_prefork.conf &lt;IfModule mpm_prefork_module&gt; StartServers 2 MinSpareServers 6 MaxSpareServers 12 MaxRequestWorkers 39 MaxConnectionsPerChild 3000&lt;/IfModule&gt;#禁用和启动模块$ sudo a2dismod mpm_event$ sudo a2enmod mpm_prefork$ sudo systemctl restart apache2 #重启Apache PHP 安装123456# 安装相关包$ sudo apt-get install php7.0 php-pear libapache2-mod-php7.0 php7.0-mysql -y# 安装组件支持apt-get install php7.0-curl php7.0-json php7.0-cgi graphviz aspell php7.0-pspell php7.0-curl php7.0-gd php7.0-intl php7.0-mysql php7.0-xml php7.0-xmlrpc php7.0-ldap php7.0-zip php7.0-soap php7.0-mbstring php-gettext -y# 重启服务$ sudo systemctl restart apache2 phpmyadmin 安装12345678910111213$ sudo apt-get install -y phpmyadmin#安装对应php包（如果没有安装对应的包）$ sudo apt-get install -y php-mbstring$ sudo apt-get install -y php-gettext#安装时选择自动配置数据库，输入数据库root账号的密码#如果不安装以上两个php软件包，则会报错或者白屏，提示找不到/usr/share/php/php-gettext/gettext.inc之类的错误#建立软连接$ sudo ln -s /usr/share/phpmyadmin /var/www/html/phpmyadmin#重启apache$ sudo /etc/init.d/apache2 restart#访问http://localhost:127.0.0.1/phpmyadmin 输入之前创建mysql 时候的账号密码即可]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 负载均衡策略]]></title>
    <url>%2F2017%2F10%2F12%2Fnginx-load-balance-strategy%2F</url>
    <content type="text"><![CDATA[Nginx 作为高性能web服务器，负载均衡是其基本功能之一。 注：负载均衡至少需要两台机器 负载均衡负载均衡可以将请求前端的请求分担到后端多个节点上，提升系统的响应和处理能力。 负载均衡策略负载均衡的策略可以大致分为两大类：内置策略 和扩展策略内置策略：一般会直接编译进Nginx内核，常用的有、轮询、ip hash、最少连接扩展策略：fair、url hash等 内置策略 轮询策略（轮询加权/round-robin）到应用服务器的请求以round-robin/轮询的方式被分发配置 123456789101112131415http &#123; # ... 省略其它配置 upstream tomcats &#123; server 192.168.0.100:8080 weight=1 fail_timeout=20s; server 192.168.0.101:8080 weight=2 fail_timeout=20s; &#125; server &#123; server_name www.searchinfogo.com listen 80; location / &#123; proxy_pass http://tomcats; &#125; &#125; # ... 省略其它配置&#125; ip hash 使用hash算法来决定下一个请求要选择哪个服务器(基于客户端IP地址)配置 12345678910111213141516http &#123; # ... 省略其它配置 upstream tomcats &#123; server 192.168.0.100:8080; server 192.168.0.101:8080; ip_hash; &#125; server &#123; server_name www.searchinfogo.com listen 80; location / &#123; proxy_pass http://tomcats; &#125; &#125; # ... 省略其它配置&#125; 最少连接（least_conn) 下一个请求将被分派到活动连接数量最少的服务器配置 12345678910111213141516http &#123; # ... 省略其它配置 upstream tomcats &#123; server 192.168.0.100:8080; server 192.168.0.101:8080; least_conn; &#125; server &#123; server_name www.searchinfogo.com listen 80; location / &#123; proxy_pass http://tomcats; &#125; &#125; # ... 省略其它配置&#125; 扩展策略 fair配置 12345678910111213141516http &#123; # ... 省略其它配置 upstream tomcats &#123; server 192.168.0.100:8080; server 192.168.0.101:8080; fair; &#125; server &#123; server_name www.searchinfogo.com listen 80; location / &#123; proxy_pass http://tomcats; &#125; &#125; # ... 省略其它配置&#125; url hash配置 1234567891011121314151617http &#123; # ... 省略其它配置 upstream tomcats &#123; server 192.168.0.100:8080; server 192.168.0.101:8080; hash $request_uri; hash_method crc32; &#125; server &#123; server_name www.searchinfogo.com listen 80; location / &#123; proxy_pass http://tomcats; &#125; &#125; # ... 省略其它配置&#125; weight=1; (weight 默认为1.weight越大，负载的权重就越大)down; (down 表示单前的server暂时不参与负载)backup; (其它所有的非backup机器down或者忙的时候，请求backup机器)max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误fail_timeout:max_fails次失败后，暂停的时间 最后1nginx -s reload #重启nginx]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos yum 安装nginx 后增加模块]]></title>
    <url>%2F2017%2F10%2F01%2Fyum-install-nginx-add-modules%2F</url>
    <content type="text"><![CDATA[yum 和 源码安装的区别yum 安装是在线安装，优点：安装方式简单，快捷； 源码安装是将源码进行编译，生成可执行文件，优点：方便的添加模块等 yum安装nginx系统版本：CentOS Linux release 7.4.1708 (Core) 1.增加对应的源1rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm 2.查看nginx信息1yum info nginx (查看nginx 版本方便后面下载对应版本) 3.yum安装nginx1yum -y install nginx nginx 相关的命令1.查看安装路径1rpm -ql nginx 2.查看编译参数1nginx -V 3.nginx 启动、停止、重启123systemctl start nginx #启动 nginx 服务systemctl stop nginx #停止 nginx 服务systemctl restart nginx #重启 nginx 服务 启动检查是否启动成功1curl -i localhost 如下显示说明正常启动：123···&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;··· 安装第三方模块其实yum安装nginx 后想要添加第三方模块，只需对yum安装的nginx相同版本的源码进行编译后替换 1.安装源码安装需要的第三方包1yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 2.下载对应的源码通过nginx -V 可以知道yum 安装nginx 的版本为1.12.1,下载对应的源码12cd /optwget http://nginx.org/download/nginx-1.12.1.tar.gz 3.查看对应configure1234567tar xf nginx-1.12.1.tar.gzcd nginx-1.12.1nginx -Vconfigure arguments: --prefix=/etc/nginx \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ ... 4.增加对应的模块12345./configure --prefix=/etc/nginx \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ ... --add-module=../headers-more-nginx-module 5.编译1make &amp;&amp; make install 6.对可执行文件进行备份替换123cp /usr/sbin/nginx /usr/sbin/nginx.bak #备份cp /opt/nginx-1.12.1/objs/nginx /usr/sbin/nginx #替换systemctl restart nginx #重启 nginx 服务 大功告成]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cannot find module './build/Release/DTraceProviderBindings']]></title>
    <url>%2F2017%2F09%2F30%2Fhexo-can't-find-module%2F</url>
    <content type="text"><![CDATA[有时候安装完hexo后， 执行命令的时候总是报错，但是不影响程序运行，但是。。。会逼死处女座，O(∩∩)O哈哈~)报错如下：123456789101112131415161718192021222324&#123; Error: Cannot find module &apos;./build/Release/DTraceProviderBindings&apos; at Function.Module._resolveFilename (module.js:527:15) at Function.Module._load (module.js:476:23) at Module.require (module.js:568:17) at require (internal/module.js:11:18) at Object.&lt;anonymous&gt; (/Users/xxx/Dropbox/hexo/node_modules/dtrace-provider/dtrace-provider.js:18:23) at Module._compile (module.js:624:30) at Object.Module._extensions..js (module.js:635:10) at Module.load (module.js:545:32) at tryModuleLoad (module.js:508:12) at Function.Module._load (module.js:500:3) at Module.require (module.js:568:17) at require (internal/module.js:11:18) at Object.&lt;anonymous&gt; (/Users/xxx/Dropbox/hexo/node_modules/bunyan/lib/bunyan.js:79:18) at Module._compile (module.js:624:30) at Object.Module._extensions..js (module.js:635:10) at Module.load (module.js:545:32) at tryModuleLoad (module.js:508:12) at Function.Module._load (module.js:500:3) at Module.require (module.js:568:17) at require (internal/module.js:11:18) at Object.&lt;anonymous&gt; (/Users/xxx/Dropbox/hexo/node_modules/hexo-log/lib/log.js:3:14) at Module._compile (module.js:624:30) code: &apos;MODULE_NOT_FOUND&apos; &#125;INFO Deleted database. 上面的错误看的非常的影响心情有木有？ 找了网上的很多方法，最后选择了一种比较粗暴的方法删除hexo目录下的node_modules目录，之后执行以下命令：1npm install --registry=https://registry.npm.taobao.org 然后执行hexo server，就会惊喜的发现错误没有了 O(∩∩)O~~)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 搭建Nexus 私服]]></title>
    <url>%2F2017%2F09%2F30%2Fdocker-install-nexus%2F</url>
    <content type="text"><![CDATA[创建数据卷1docker volume create --name nexus-data 拉取Nexus 镜像1docker pull sonatype/nexus3 ( 国内建议使用daocloud，centos 可以使用dao pull sonatype/nexus3) 启动镜像1docker run --restart="always" -d -p 8081:8081 --name nexus -v nexus-data:/nexus-data sonatype/nexus3 访问网址打开(账号/密码 admin/admin123)http://localhost:8081 参考https://hub.docker.com/r/sonatype/nexus3/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装MongoDB(Mongo3.x)]]></title>
    <url>%2F2017%2F09%2F23%2Fdocker-install-MongoDB%2F</url>
    <content type="text"><![CDATA[使用Volume(Volume 比 普通的挂载磁盘有很多优势，这里采用Volume)创建Volume 命名为mongo-data1docker volume create --name mongo-data 拉取镜像1docker pull mongo 运行1234567docker run --restart=&quot;always&quot; \ -d \ --name mongo\ -p 17017:27017\ -v mongo-data:/data/db\ -v /etc/localtime:/etc/localtime\ mongo:latest --storageEngine wiredTiger -auth --storageEngine MongoDB 的存储引擎，具体请查阅官方文档,此处采用wiredTiger，将数据存储到磁盘-auth 设置Mongo的权限 进入mongo镜像1docker exec -it mongo mongo admin 创建用户 user123 密码:1234561db.createUser(&#123;user: &quot;user123&quot;,pwd: &quot;123456&quot;,roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125; ]&#125;) 至此，MongDB 安装完成]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis连接池连接没有正常释放报错]]></title>
    <url>%2F2017%2F09%2F23%2FCould-not-get-a-resource-from-the-pool%2F</url>
    <content type="text"><![CDATA[123456Caused by: redis.clients.jedis.exceptions.JedisException: Could not get a resource from the poolat redis.clients.util.Pool.getResource(Pool.java:51)at redis.clients.jedis.JedisPool.getResource(JedisPool.java:226)at redis.clients.jedis.JedisPool.getResource(JedisPool.java:16)at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:194)... 71 common frames omitted 前几天在线上碰到了一个奇怪的问题，jedis 突然无法从连接池取到资源，经过排查发现是因为使用分布式锁的时候,没有释放资源 redisTemplate 和 jedis 不同redisTemplate 自己实现了资源的释放，不需要像jedis一样手动释放 12345678public boolean setNX(final String key, final String value) throws RedisException &#123; return redisTemplate.execute(new RedisCallback&lt;Boolean&gt;() &#123; @Override public Boolean doInRedis(RedisConnection redisConnection) throws DataAccessException &#123; return redisConnection.setNX(key.getBytes(), value.getBytes()); &#125; &#125;); &#125; 所以实现分布式锁的时候需要调用redisTemplate.execute 让 redisTemplate 帮我们释放资源，具体的可以看redisTemplate 的源码。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生活]]></title>
    <url>%2F2017%2F09%2F23%2Flife%2F</url>
    <content type="text"><![CDATA[日常生活趣事记录]]></content>
      <categories>
        <category>Other</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 504 Gateway Time-out]]></title>
    <url>%2F2017%2F09%2F22%2FLinux%2F</url>
    <content type="text"><![CDATA[今天碰到了一个问题，生产环境用户报错，后台看日志都是正常的，最后经过debug 发现是nginx 设置1proxy_connect_timeout = 3; 时间过小导致的，最好用默认参数]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
</search>
